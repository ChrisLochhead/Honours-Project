default: 
   trainer: ppo 
   batch_size: 123
   beta: 1.0e-2 
   buffer_size: 1230
   epsilon: 0.15 
   hidden_units: 123
   lambd: 0.92 
   learning_rate: 123
   max_steps: 123
   memory_size: 256 
   normalize: false 
   num_epoch: 123
   num_layers: 0
   time_horizon: 64 
   sequence_length: 64 
   summary_freq: 1250 
   use_recurrent: false 
   vis_encode_type: simple 
   reward_signals: 
       extrinsic: 
           strength: 1.0 
           gamma: 0.99 
       curiosity: 
           strength: 0.01 
           gamma: 0.99 
           encoding_size: 256