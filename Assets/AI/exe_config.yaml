default: 
   trainer: ppo 
   batch_size: 120
   beta: 1.0e-2 
   buffer_size: 1200
   epsilon: 0.15 
   hidden_units: 256
   lambd: 0.92 
   learning_rate: 0.0001
   max_steps: 1250
   memory_size: 256 
   normalize: false 
   num_epoch: 3
   num_layers: 0
   time_horizon: 64 
   sequence_length: 64 
   summary_freq: 1250 
   use_recurrent: false 
   vis_encode_type: simple 
   reward_signals: 
       extrinsic: 
           strength: 1.0 
           gamma: 0.99 
       curiosity: 
           strength: 0.01 
           gamma: 0.99 
           encoding_size: 256